# Stats101CProject

This project was done as a team for my UCLA Stats 101C class (Introduction to Statistical Models and Data Mining) through a Kaggle competition about predicting affordability of homes in Ames, Iowa, given 80 predictor variables. 

HTrainLast.csv was our given training data for homes with which we created our prospective models. 
HTestLastNoY.csv was our given testing data from predicting affordability.
newcleanfull.csv was the cleaned training data we created primarily by variable transformations, filling in missing values, and creating new and more informative variables. 
The Plots R Markdown shows our initial exploratory analysis of all variables versus the dependent variable in ggplot. 
The logistic regression R Markdown is all of our cleaning, modelling, and testing of the data. 
superprediction2.csv was our final prediction data that gave us the highest Kaggle score of 98.2% accuracy in our predictions.

Finally, The Dummy Variables PDF was our final presentation explaining our methods and findings. 
